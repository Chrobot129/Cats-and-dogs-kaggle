{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from keras import layers\nfrom keras import models\nfrom keras import optimizers\nfrom keras.preprocessing.image import ImageDataGenerator\nimport os, shutil\nimport zipfile\n\nfrom keras.callbacks import EarlyStopping, ReduceLROnPlateau\n\nimg_rows = 150\nimg_cols = 150\n\n\n","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with zipfile.ZipFile(\"/kaggle/input/dogs-vs-cats/train.zip\") as train:\n    train.extractall(\".\")\nwith zipfile.ZipFile(\"/kaggle/input/dogs-vs-cats/test1.zip\") as test:\n    test.extractall(\".\")    ","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt  \n    \ndef PlotTwoAccuracyComparison(acc1, val_acc1, acc2, val_acc2, lab1 = 'Model 1', lab2 = 'Model 2'):\n    plt.clf()   \n    \n    plt.rcParams['figure.figsize'] = (25.0, 5.0) \n    epochs = range(len(acc1))\n    \n    plt.plot(epochs, acc1, 'bo', label='Training accuracy for ' + lab1)\n    plt.plot(epochs, val_acc1, 'b', label='Validation accuracy for ' + lab1)\n    plt.plot(epochs, acc2, 'ro', label='Training accuracy for ' + lab2)\n    plt.plot(epochs, val_acc2, 'r', label='Validation accuracy for ' + lab2)\n    plt.title('Comparison of Training and Validation Accuracies')\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy')\n    plt.legend(['Train', 'Test'], loc='upper left')\n    plt.show()\n    \ndef PlotTwoLossComparison(loss1, val_loss1, loss2, val_loss2, lab1 = 'Model 1', lab2 = 'Model 2'):\n    plt.clf()   \n    \n    plt.rcParams['figure.figsize'] = (25.0, 5.0) \n    epochs = range(len(loss1))\n    \n    plt.plot(epochs, loss1, 'bo', label='Training loss for ' + lab1)\n    plt.plot(epochs, val_loss1, 'b', label='Validation loss for ' + lab1)\n    plt.plot(epochs, loss2, 'ro', label='Training loss for ' + lab2)\n    plt.plot(epochs, val_loss2, 'r', label='Validation loss for ' + lab2)\n    plt.title('Comparison of Training and Validation Losses')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend(['Train', 'Test'], loc='upper left')\n    plt.show()","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nmodels_dir = '/kaggle/working/models/'\nif not os.path.exists(models_dir):\n    os.mkdir(models_dir)\n\n\noriginal_dataset_dir = '/kaggle/working/train/'\n\nbase_dir = '/kaggle/working/cats_and_dogs_8000/'\nif not os.path.exists(base_dir):\n    os.mkdir(base_dir)\n\ntrain_dir = os.path.join(base_dir, 'train')\nif not os.path.exists(train_dir):\n    os.mkdir(train_dir)\n    \nvalidation_dir = os.path.join(base_dir, 'validation')\nif not os.path.exists(validation_dir):\n    os.mkdir(validation_dir)\n    \ntest_dir = os.path.join(base_dir, 'test1')\nif not os.path.exists(test_dir):\n    os.mkdir(test_dir)\n\ntrain_cats_dir = os.path.join(train_dir, 'cats')\nif not os.path.exists(train_cats_dir):\n    os.mkdir(train_cats_dir)\n\ntrain_dogs_dir = os.path.join(train_dir, 'dogs')\nif not os.path.exists(train_dogs_dir):\n    os.mkdir(train_dogs_dir)\n\nvalidation_cats_dir = os.path.join(validation_dir, 'cats')\nif not os.path.exists(validation_cats_dir):\n    os.mkdir(validation_cats_dir)\n\nvalidation_dogs_dir = os.path.join(validation_dir, 'dogs')\nif not os.path.exists(validation_dogs_dir):\n    os.mkdir(validation_dogs_dir)\n\ntest_cats_dir = os.path.join(test_dir, 'cats')\nif not os.path.exists(test_cats_dir):\n    os.mkdir(test_cats_dir)\n\ntest_dogs_dir = os.path.join(test_dir, 'dogs')\nif not os.path.exists(test_dogs_dir):\n    os.mkdir(test_dogs_dir)\n\nfnames = ['cat.{}.jpg'.format(i) for i in range(4000)]\nfor fname in fnames:\n    src = os.path.join(original_dataset_dir, fname)\n    dst = os.path.join(train_cats_dir, fname)\n    shutil.copyfile(src, dst)\n\nfnames = ['cat.{}.jpg'.format(i) for i in range(4000, 6000)]\nfor fname in fnames:\n    src = os.path.join(original_dataset_dir, fname)\n    dst = os.path.join(validation_cats_dir, fname)\n    shutil.copyfile(src, dst)\n    \nfnames = ['cat.{}.jpg'.format(i) for i in range(6000, 8000)]\nfor fname in fnames:\n    src = os.path.join(original_dataset_dir, fname)\n    dst = os.path.join(test_cats_dir, fname)\n    shutil.copyfile(src, dst)\n    \nfnames = ['dog.{}.jpg'.format(i) for i in range(4000)]\nfor fname in fnames:\n    src = os.path.join(original_dataset_dir, fname)\n    dst = os.path.join(train_dogs_dir, fname)\n    shutil.copyfile(src, dst)\n    \nfnames = ['dog.{}.jpg'.format(i) for i in range(4000, 6000)]\nfor fname in fnames:\n    src = os.path.join(original_dataset_dir, fname)\n    dst = os.path.join(validation_dogs_dir, fname)\n    shutil.copyfile(src, dst)\n    \nfnames = ['dog.{}.jpg'.format(i) for i in range(6000, 8000)]\nfor fname in fnames:\n    src = os.path.join(original_dataset_dir, fname)\n    dst = os.path.join(test_dogs_dir, fname)\n    shutil.copyfile(src, dst)\n","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model8k = models.Sequential()\nmodel8k.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_rows, img_cols, 3)))\nmodel8k.add(layers.BatchNormalization())\nmodel8k.add(layers.MaxPooling2D((2, 2)))\nmodel8k.add(layers.Dropout(0.1))\n\nmodel8k.add(layers.Conv2D(64, (3, 3), activation='relu'))\nmodel8k.add(layers.BatchNormalization())\nmodel8k.add(layers.MaxPooling2D((2, 2)))\nmodel8k.add(layers.Dropout(0.15))\n\nmodel8k.add(layers.Conv2D(128, (3, 3), activation='relu'))\nmodel8k.add(layers.BatchNormalization())\nmodel8k.add(layers.MaxPooling2D((2, 2)))\nmodel8k.add(layers.Dropout(0.20))\n\nmodel8k.add(layers.Conv2D(128, (3, 3), activation='relu'))\nmodel8k.add(layers.BatchNormalization())\nmodel8k.add(layers.MaxPooling2D((2, 2)))\nmodel8k.add(layers.Dropout(0.25))\n\nmodel8k.add(layers.Conv2D(256, (3, 3), activation='relu'))\nmodel8k.add(layers.BatchNormalization())\nmodel8k.add(layers.MaxPooling2D((2, 2)))\nmodel8k.add(layers.Flatten())\nmodel8k.add(layers.Dropout(0.5))\n\nmodel8k.add(layers.Dense(512, activation='relu'))\nmodel8k.add(layers.Dense(1, activation='sigmoid'))\n\nmodel8k.compile(loss='binary_crossentropy',\n              optimizer=optimizers.RMSprop(lr=1e-3),\n              metrics=['acc'])\nmodel8k.summary()\n","execution_count":11,"outputs":[{"output_type":"stream","text":"Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d (Conv2D)              (None, 148, 148, 32)      896       \n_________________________________________________________________\nbatch_normalization (BatchNo (None, 148, 148, 32)      128       \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) (None, 74, 74, 32)        0         \n_________________________________________________________________\ndropout (Dropout)            (None, 74, 74, 32)        0         \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 72, 72, 64)        18496     \n_________________________________________________________________\nbatch_normalization_1 (Batch (None, 72, 72, 64)        256       \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 36, 36, 64)        0         \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 36, 36, 64)        0         \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 34, 34, 128)       73856     \n_________________________________________________________________\nbatch_normalization_2 (Batch (None, 34, 34, 128)       512       \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, 17, 17, 128)       0         \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 17, 17, 128)       0         \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, 15, 15, 128)       147584    \n_________________________________________________________________\nbatch_normalization_3 (Batch (None, 15, 15, 128)       512       \n_________________________________________________________________\nmax_pooling2d_3 (MaxPooling2 (None, 7, 7, 128)         0         \n_________________________________________________________________\ndropout_3 (Dropout)          (None, 7, 7, 128)         0         \n_________________________________________________________________\nconv2d_4 (Conv2D)            (None, 5, 5, 256)         295168    \n_________________________________________________________________\nbatch_normalization_4 (Batch (None, 5, 5, 256)         1024      \n_________________________________________________________________\nmax_pooling2d_4 (MaxPooling2 (None, 2, 2, 256)         0         \n_________________________________________________________________\nflatten (Flatten)            (None, 1024)              0         \n_________________________________________________________________\ndropout_4 (Dropout)          (None, 1024)              0         \n_________________________________________________________________\ndense (Dense)                (None, 512)               524800    \n_________________________________________________________________\ndense_1 (Dense)              (None, 1)                 513       \n=================================================================\nTotal params: 1,063,745\nTrainable params: 1,062,529\nNon-trainable params: 1,216\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n                                            patience=2, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.00001)","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_datagen = ImageDataGenerator(\n    rescale=1./255,\n    shear_range=0.1,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    width_shift_range=0.1,\n    height_shift_range=0.1)\n\n# Note that the validation data should not be augmented!\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\ntrain_generator = train_datagen.flow_from_directory(\n        # This is the target directory\n        train_dir,\n        # All images will be resized to 150x150\n        target_size=(img_rows, img_cols),\n        batch_size=32,\n        # Since we use binary_crossentropy loss, we need binary labels\n        class_mode='binary')\n\nvalidation_generator = test_datagen.flow_from_directory(\n        validation_dir,\n        target_size=(img_rows, img_cols),\n        batch_size=32,\n        class_mode='binary')","execution_count":13,"outputs":[{"output_type":"stream","text":"Found 8000 images belonging to 2 classes.\nFound 4000 images belonging to 2 classes.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"history8k = model8k.fit_generator(\n      train_generator,\n      steps_per_epoch=train_generator.samples/train_generator.batch_size,\n      epochs=100,\n      validation_data=validation_generator,\n      validation_steps=validation_generator.samples//validation_generator.batch_size,\n      callbacks = learning_rate_reduction)","execution_count":null,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n  warnings.warn('`Model.fit_generator` is deprecated and '\n","name":"stderr"},{"output_type":"stream","text":"Epoch 1/100\n250/250 [==============================] - 69s 258ms/step - loss: 1.2841 - acc: 0.5456 - val_loss: 0.9169 - val_acc: 0.5025\nEpoch 2/100\n250/250 [==============================] - 65s 261ms/step - loss: 0.6394 - acc: 0.6447 - val_loss: 0.7988 - val_acc: 0.5590\nEpoch 3/100\n103/250 [===========>..................] - ETA: 32s - loss: 0.5612 - acc: 0.7240","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model8k.save(models_dir + 'cats_and_dogs_8k_2.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc8k = history8k.history['acc']\nval_acc8k = history8k.history['val_acc']\nloss8k = history8k.history['loss']\nval_loss8k = history8k.history['val_loss']\n\nprint(val_acc8k)\n\nPlotAccuracyComparison(acc8k, val_acc8k, lab = 'Model 8k')\nPlotLossComparison(loss8k, val_loss8k, lab = 'Model 8k')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}